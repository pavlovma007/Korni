

# Эксперименты с размером

`to csv` -  не очень нужная штука. надо по идее в обратную сторону. 

## spyql to csv 

	time sqlite3 -header -csv kladr.db "select * from DOMA;"  >doma.csv 
	real	0m22,893s
	user	0m7,945s
	sys	0m2,087s

`sqlite3` быстрая штука

## sqlite-utils to csv 

	time sqlite-utils rows kladr.db DOMA --csv > doma2.csv #--limit 10 --offset 1 -t
	real	2m35,887s
	user	0m24,808s
	sys	0m1,866s

## sqlite3 to csv  FASTER   (немного больше кавычек генерирует)

	time sqlite3 -header -csv kladr.db "select * from DOMA;" > doma.csv 
	real	0m45,020s
	user	0m8,083s
	sys	0m1,194s

## размер оригинального файла

	ll -h doma.csv 
	-rw-rw-r-- 1 mp mp 354M мая 24 20:52 doma.csv

354M

## добавим и посмотрим размеры , если git

	$ git add doma.csv 
	$ du -sh .git/ 
	65M	.git/
	$ ls -R -lh  .git/
	.git/:
	итого 36K
	drwxrwxr-x 2 mp mp 4,0K мая 24 20:38 branches
	-rw-rw-r-- 1 mp mp   92 мая 24 20:38 config
	-rw-rw-r-- 1 mp mp   73 мая 24 20:38 description
	-rw-rw-r-- 1 mp mp   23 мая 24 20:38 HEAD
	drwxrwxr-x 2 mp mp 4,0K мая 24 20:38 hooks
	-rw-rw-r-- 1 mp mp  104 мая 24 20:57 index
	drwxrwxr-x 2 mp mp 4,0K мая 24 20:38 info
	drwxrwxr-x 5 mp mp 4,0K мая 24 20:56 objects
	drwxrwxr-x 4 mp mp 4,0K мая 24 20:38 refs
	
	.git/branches:
	итого 0
	
	.git/hooks:
	итого 52K
	-rwxrwxr-x 1 mp mp  478 мая 24 20:38 applypatch-msg.sample
	-rwxrwxr-x 1 mp mp  896 мая 24 20:38 commit-msg.sample
	-rwxrwxr-x 1 mp mp 3,1K мая 24 20:38 fsmonitor-watchman.sample
	-rwxrwxr-x 1 mp mp  189 мая 24 20:38 post-update.sample
	-rwxrwxr-x 1 mp mp  424 мая 24 20:38 pre-applypatch.sample
	-rwxrwxr-x 1 mp mp 1,6K мая 24 20:38 pre-commit.sample
	-rwxrwxr-x 1 mp mp  416 мая 24 20:38 pre-merge-commit.sample
	-rwxrwxr-x 1 mp mp 1,5K мая 24 20:38 prepare-commit-msg.sample
	-rwxrwxr-x 1 mp mp 1,4K мая 24 20:38 pre-push.sample
	-rwxrwxr-x 1 mp mp 4,8K мая 24 20:38 pre-rebase.sample
	-rwxrwxr-x 1 mp mp  544 мая 24 20:38 pre-receive.sample
	-rwxrwxr-x 1 mp mp 3,6K мая 24 20:38 update.sample
	
	.git/info:
	итого 4,0K
	-rw-rw-r-- 1 mp mp 240 мая 24 20:38 exclude
	
	.git/objects:
	итого 12K
	drwxrwxr-x 2 mp mp 4,0K мая 24 20:57 b7
	drwxrwxr-x 2 mp mp 4,0K мая 24 20:38 info
	drwxrwxr-x 2 mp mp 4,0K мая 24 20:38 pack
	
	.git/objects/b7:
	итого 64M
	-r--r--r-- 1 mp mp 64M мая 24 20:57 6c8101cc7cf3530a40956a0417788761dc0711
	
	.git/objects/info:
	итого 0
	
	.git/objects/pack:
	итого 0
	
	.git/refs:
	итого 8,0K
	drwxrwxr-x 2 mp mp 4,0K мая 24 20:38 heads
	drwxrwxr-x 2 mp mp 4,0K мая 24 20:38 tags
	
	.git/refs/heads:
	итого 0
	
	.git/refs/tags:
	итого 0

т.е.  файл 354МБ в гит стал 64МБ в объектах. 
превратим это в pack - уплотнение 

	$ find .git/objects -type f
	.git/objects/b7/6c8101cc7cf3530a40956a0417788761dc0711
	
	$ git repack   # objects -> packs 
	Перечисление объектов: 1, готово.
	Подсчет объектов: 100% (1/1), готово.
	Запись объектов: 100% (1/1), готово.
	Всего 1 (изменения 0), повторно использовано 0 (изменения 0)
	
	$ du -sh .git 
	112M	.git # стало больше ! 
	
	$ find .git/objects -type f  | xargs ls -lh 
	-r--r--r-- 1 mp mp  64M мая 24 20:57 .git/objects/b7/6c8101cc7cf3530a40956a0417788761dc0711
	-rw-rw-r-- 1 mp mp   54 мая 24 22:33 .git/objects/info/packs
	-r--r--r-- 1 mp mp 1,1K мая 24 22:33 .git/objects/pack/pack-401969cbe11306d1f0f486b6f40557492e8c0f27.idx
	-r--r--r-- 1 mp mp  48M мая 24 22:33 .git/objects/pack/pack-401969cbe11306d1f0f486b6f40557492e8c0f27.pack
	
	# тут теперь и objects  и pack + idx 
	
	$ git gc 
	Перечисление объектов: 1, готово.
	Подсчет объектов: 100% (1/1), готово.
	Запись объектов: 100% (1/1), готово.
	Всего 1 (изменения 0), повторно использовано 1 (изменения 0)
	
	$ du -hs .git/
	48M	.git/ 
	
	# место стало компактнее 
	
	$ find .git/objects -type f  | xargs ls -lh 
	-rw-rw-r-- 1 mp mp   54 мая 24 22:33 .git/objects/info/packs
	-r--r--r-- 1 mp mp 1,1K мая 24 22:36 .git/objects/pack/pack-401969cbe11306d1f0f486b6f40557492e8c0f27.idx
	-r--r--r-- 1 mp mp  48M мая 24 22:36 .git/objects/pack/pack-401969cbe11306d1f0f486b6f40557492e8c0f27.pack
	
	# теперь только pack + idx  и всё сжато 
	
	# проверим 
	$ find .git/objects -type f  | grep '.pack$' | xargs git verify-pack -v 
	b76c8101cc7cf3530a40956a0417788761dc0711 blob   370852249 49840440 12
	не дельты: 1 объект
	.git/objects/pack/pack-401969cbe11306d1f0f486b6f40557492e8c0f27.pack: ok
	
	$ git fsck --full
	Проверка каталогов объектов: 100% (256/256), готово.
	Проверка объектов: 100% (1/1), готово.
	notice: HEAD points to an unborn branch (master)
	notice: No default references
	
	$ git count-objects -v
	count: 0
	size: 0
	in-pack: 1
	packs: 1
	size-pack: 48673
	prune-packable: 0
	garbage: 0
	size-garbage: 0
	# size-pack: 48673 # тут видимо в КилоБайтах
	
	$ find .git/objects -type f  | grep '.idx$' | xargs git verify-pack -v 
	b76c8101cc7cf3530a40956a0417788761dc0711 blob   370852249 49840440 12
	не дельты: 1 объект
	.git/objects/pack/pack-401969cbe11306d1f0f486b6f40557492e8c0f27.pack: ok


	$ git commit -m 'init'
	
	$ git verify-pack -v .git/objects/pack/pack-*.idx   | sort -k 3 -n   | tail -3
	.git/objects/pack/pack-401969cbe11306d1f0f486b6f40557492e8c0f27.pack: ok
	не дельты: 1 объект
	b76c8101cc7cf3530a40956a0417788761dc0711 blob   370852249 49840440 12




	# тут тоже этот объект присутствует . ЭТО ВСЕ ОБЪЕКТЫ ГИТА:
	
	$ git rev-list --objects --all
	020381fa94b30f2b688126b1acb79295e3e525c3    		# <- commit 
	22878db71659c2f90be17bbe7077dc43758f7c01     		# <- tree \ blob's hashas
	b76c8101cc7cf3530a40956a0417788761dc0711 doma.csv	# <- blob data 
	
	$ git cat-file -p 020381fa94b30f2b688126b1acb79295e3e525c3
	tree 22878db71659c2f90be17bbe7077dc43758f7c01		# BLOB LIST | TREE
	author Mikhail Pavlov <pavlovma007@gmail.com> 1653421604 +0300
	committer Mikhail Pavlov <pavlovma007@gmail.com> 1653421604 +0300
	
	$ git cat-file -p 22878db71659c2f90be17bbe7077dc43758f7c01
	100644 blob b76c8101cc7cf3530a40956a0417788761dc0711	doma.csv   # <- file blob id 
	
	$ git cat-file -p b76c8101cc7cf3530a40956a0417788761dc0711 | tail -3
	"8б","","ДОМ",9900000000000470001,468325,9901,"",55000000000
	1,"","ДОМ",9900000000000470002,"",9901,"",55000000000
	3,"","ДОМ",9900000000000510001,468321,9901,"",55000000000


	$ git cat-file -p b76c8101cc7cf3530a40956a0417788761dc0711 | head -n 10 | spyql -Otable=doma -Ochunk_size=1 --unbuffered 'select * from csv to sql  '
	INSERT INTO "doma"("NAME","KORP","SOCR","CODE","IINDEX","GNINMB","UNO","OCATD") VALUES ('15Лстр1,4Б,8Астр10,8Астр426','','ДОМ',100000100000030001,385000,100,'',79401000000);
	INSERT INTO "doma"("NAME","KORP","SOCR","CODE","IINDEX","GNINMB","UNO","OCATD") VALUES ('1,10,103,11В,12,15,15Б,16,17,17А,20,22','','ДОМ',100000100000030002,385006,100,'',79401000000);
	INSERT INTO "doma"("NAME","KORP","SOCR","CODE","IINDEX","GNINMB","UNO","OCATD") VALUES ('23,3,39,39А,47А,4Б/1,4Бстр10,4Бстр11','','ДОМ',100000100000030003,385006,100,'',79401000000);
	INSERT INTO "doma"("NAME","KORP","SOCR","CODE","IINDEX","GNINMB","UNO","OCATD") VALUES ('4Бстр12,4Бстр13,4Бстр14,4Бстр15,4Бстр16','','ДОМ',100000100000030004,385006,100,'',79401000000);
	INSERT INTO "doma"("NAME","KORP","SOCR","CODE","IINDEX","GNINMB","UNO","OCATD") VALUES ('4Бстр17,4Бстр18,4Бстр19,4Бстр2,4Бстр20','','ДОМ',100000100000030005,385006,100,'',79401000000);
	INSERT INTO "doma"("NAME","KORP","SOCR","CODE","IINDEX","GNINMB","UNO","OCATD") VALUES ('4Бстр21,4Бстр22,4Бстр23,4Бстр24,4Бстр25','','ДОМ',100000100000030006,385006,100,'',79401000000);
	INSERT INTO "doma"("NAME","KORP","SOCR","CODE","IINDEX","GNINMB","UNO","OCATD") VALUES ('4Бстр26,4Бстр27,4Бстр28,4Бстр29,4Бстр3','','ДОМ',100000100000030007,385006,100,'',79401000000);
	INSERT INTO "doma"("NAME","KORP","SOCR","CODE","IINDEX","GNINMB","UNO","OCATD") VALUES ('4Бстр30,4Бстр31,4Бстр32,4Бстр4,4Бстр5','','ДОМ',100000100000030008,385006,100,'',79401000000);
	INSERT INTO "doma"("NAME","KORP","SOCR","CODE","IINDEX","GNINMB","UNO","OCATD") VALUES ('4Бстр6,4Бстр7,4Бстр8,4Бстр9,5,6,6стр85,7','','ДОМ',100000100000030009,385006,100,'',79401000000);

!!! Важно, если данные только пополняются в бд то не нужно ничего мержить. не нужен актуальный дамп базы - надо объединить множества записей. 
объединить множество актуальных записей от разных пользователей. 
а потом сделать gc. 

понятно, что будут "исторические записи" и "актуальные записи". 
Записи должны быть подписаны. 

GIT нужен чтобы у каждого была СВОЯ ИЗМЕНЯЕМАЯ БАЗА ДАННЫХ . 
а по идее если БД есть результат выполнения журнала (?kafka) то достаточно объединения записей и вычисления на основе этого "своего слепка БД."

> мнение: в систему `git` не надо встраивать! пусть каждый юзер , если хочет, использует его. если для всех этот механизм  использовать, то это пародит проблемы с мержем.... 
>
> лучше сделать многоверсионность и дать ее людям - это более гибко. 




Эксперимент (ipfs  не дедублицирует части архивов)
-----------------------------------------------------

#### для tar.gz архива 

я сделал образ докера и сохранил его в tar.gz - 1.1 ГБ, образ. 
потом я добавил команды в Dockerfile тоже сохранил образ в tar.gz 1.5 ГБ получилось уже, образ. 
это два tgz архива у которых большая часть начальных файлов та же самая. 

далее  я сделал ipfs репозитарий и добавил их в него. 
в ipfs  есть система разбтия контента на блоки, примерно не более 260КБ, блоки "дедуплицируются" при повторном повторении в других файлах. 

	ipfs add korni_app_editor-NoBraveBrowser.tar.gz korni_app_editor.tar.gz 
	added QmUz8sDD7AxBSXfmWZ8WP9bzdFauMGKvha1c8nRgufNqBo korni_app_editor-NoBraveBrowser.tar.gz
	added QmRWmGaR9oLUmbPqzoxLZuxb978VMyKv5aL1hvV4CuD5zC korni_app_editor.tar.gz

**вопрос: на сколько эффективно получается дедублировать контент таким образом ?** 

**ответ: не особо**. изначально есть на диске два файла :

	$ ll -h korni_app_editor*
	-rw-rw-r-- 1 mp mp 362M мая 15 13:22 korni_app_editor-NoBraveBrowser.tar.gz
	-rw-rw-r-- 1 mp mp 528M мая 25 10:05 korni_app_editor.tar.gz

в сумме 890 МБ. есть ipfs репозитарий с блоками:

	$ du -hs ipfs/
	908M	ipfs/

!!! **Это странно, но для архивов, видимо, такой метод дедубликации не стабатывает**


#### для простого tar архива это должно срабатывать

	$ zcat korni_app_editor.tar.gz > korni_app_editor.tar
	$ zcat korni_app_editor-NoBraveBrowser.tar.gz > korni_app_editor-NoBraveBrowser.tar
	$ rm -rf ipfs/*
	$ ipfs init 
	generating ED25519 keypair...done
	peer identity: 12D3KooWQqQWqtQpggPeSAq1ijxYLsEwJfkzCaJAkciJZ1avAAZh
	initializing IPFS node at ./ipfs
	to get started, enter:
	
		ipfs cat /ipfs/QmQPeNsJPyVWPFDVHb77w8G42Fvo15z4bG2X8D2GhfbSXc/readme
	
	$ ipfs add korni_app_editor.tar korni_app_editor-NoBraveBrowser.tar
	added QmfSX89TBbF8KdbYVPYrH71qVNnn6JcBsWVmhGp5gDYkrA korni_app_editor-NoBraveBrowser.tar
	added QmVKD18YqaAftH9rb99nMLKA7rGBWqM8rmD9Q4a6pfjhaL korni_app_editor.tar
	 2.33 GiB / 2.33 GiB [===============================================] 100.00%
	$ du -sh ipfs/
	2,0G	ipfs/

экономия от дедубликации очень не существенная  2.3ГБ превратилось в 2.0ГБ. 
блоков стало много 

	$ find  ./ipfs -type f | wc -l 
	7811

Итого : **ipfs тупой, он не ищет diff в блоках. если сместить в файле контент 
 хоть на один байт деление на блоки методом "по размеру" выдаст в этом месте другой контент**

**ipfs нельзя использовать для экономии места, он помогает в этом по возможности, но в основном для одинаковых файлов, 
а не для похожих файлов**

> для тайлов карт он кстати подходит т.к. там много одинаковых файлов



Вариант файловой структуры 
==============================

**требования:** 

* изменения надо забирать по дате  (год + 365 дней в году)
* по пользователю (миллиарды пользователей). 

1000-30000 файлов в папке - работает нормально. 

сколько надо уровней, чтобы 500-000-000 миллионов аккаунтов удобно разделить? 

	log(base(3000), 500000000) < 3 
	log(base(1000), 500000000) < 3 

и только 

	log(base(30000), 500000000) < 2

логично добавить ТРИ уровня каталогов для идентификаторов пользователей в каждом из которых будет примерно по 4000 файлов.

Сколько идентификаторов пользователей удобно поместить в три уровня каталогов где в каждом по 4000 файлов? 


	log(base(4000), 20_000_000_000) = 2.86
	Math.pow(4000, 3) = 64-000-000-000

т.е. трёх уровней каталогов достаточно чтобы уместить более 20 миллиардов аккаунтов. 

> если userid кодировать hexdigit (sha hash as string)  то `16*16=256`;   `16*16*16=4096`  `4096*16=65536` 
>
> **3  символа = нормально , 4 уже много!** 
>
> буду кодировать блоками по 3 символа


  При таком раскладе логично иметь подобную структуру каталогов и именование файлов: (тут ipfs id взят за основу)

	2022/2022-05-22/QmVKD18Y/qaAftH9r/b99nMLKA7rGBWqM8rmD9Q4a6pfjhaL/node-2022-05-22-pavlovma007.csv.gz

Это 100 байт в листинге файлов на изменения одного дня одного юзера

если меня интересуют обновления от 1000 человек (друзья) то список файлов будет 100КБайт. 
Сами файлы возможно больше, но это уже не так существенно. 

**требования**:

* хорошо бы указывать в пути "регион", в котором создан этот контент, чтобы сразу фильтровать все изменения по региону

точно стоит воткнуть geohash : координата 58.05139/38.83802 станет uf7d5zbvz7q   https://en.wikipedia.org/wiki/Geohash
	
	2022/2022-05-22/QmVKD18Y/qaAftH9r/b99nMLKA7rGBWqM8rmD9Q4a6pfjhaL/T-node-GH-uf7d5zbvz7q.csv.gz

тогда по списку файлов можно фильтровать те записи юзеров которые относятся к этому региону..
Хорошо ли это ? замыкается ли 

Запрос контента
=================

* записи 
    * создаются , шифруются или нет , подписываются и идентифицируются по `korni-id uuid` или по sha256 (это даже лучше) так не получится изменить запись. 
    * внутри записи есть 
      * поле юзер, 
      * дата создания, 
      * поле имя для заплатки, 
      * значение,
      * ссылки на объекты (идентификаторы объектов, внешние ссылки)
    * в результате расчёта получается id записи - он стабилен и определен контентом. 
* 
* списки записей хранятся в csv.gz файлах и разделяются между юзерами, эти списки идентифицируются датой, юзером, 

**возникает проблема: ? как "в общей файловой помойке" обнаружить заданный объект по его идентификатору?**

мысль: объекты логично разложть тоже в структуру папок на подобие списка файлов, но хочется иметь возможность p2p раздавать и получать объекты

есть разные типы кешей: возможно ид объекта должен содержать все эти типы... 

пример идентификатора


	$ sha256sum korni_app_editor.tar
	76ac4be60275b9ae272b33bb1f6d896bb82c0b8de3312dfc7d1c0238f815f2ad  korni_app_editor.tar
	$ sha256sum -b korni_app_editor.tar
	76ac4be60275b9ae272b33bb1f6d896bb82c0b8de3312dfc7d1c0238f815f2ad  *korni_app_editor.tar
	$ md5sum korni_app_editor.tar
	6a7da134e822da8a5e8fd0e70601d5c0  korni_app_editor.tar
	$ md5sum -b korni_app_editor.tar
	6a7da134e822da8a5e8fd0e70601d5c0 *korni_app_editor.tar
	
	$ transmission-create korni_app_editor.tar &>/dev/null  && transmission-show korni_app_editor.tar.torrent | grep 'Hash:'|awk '{print $2}'
	7bac1d7ca579214232065d8e5fb0c09ae9896282
	
	GFS-QmVKD18YqaAftH9rb99nMLKA7rGBWqM8rmD9Q4a6pfjhaL-T-7bac1d7ca579214232065d8e5fb0c09ae9896282-M-6a7da134e822da8a5e8fd0e70601d5c0-S256-76ac4be60275b9ae272b33bb1f6d896bb82c0b8de3312dfc7d1c0238f815f2ad

**получается 200 символов ТОЛЬКО на идентификатор** `GFS-<ipfs>-T-<torrentHash>-M-<md5>-S256-<sha256>`

это примерно 500-1000 байт на одну сохраненную правку. 

для торрента характерно , **если поменять имя входных файлов, то хеш изменится** - он считается не только по содержимому. 
поэтому **воткнуть хеш в имя файлов не получится**

логично иметь общую таблицу о файлах и объектах с такими полями 

* path
* gfs-hash
* torrent-hash 
* sha256 
* md5 
* isFile
* objectType str OR typeuuid

но если там будет что-то кроме хешей, например , путь, то злоумышленники туда напишут всякое. 

Прямые соединения возможны
==========================

если публичный ключ юзера 
	AAAAB3NzaC1yc2EAAAADAQABAAABAQCaz6MssQyb1DzO7BjfcUrklXHVRkfmU5RUmLTaCXwCCp1o7atRXzkMTL/8aZSci/V8/knQUm7q6cQSHlkrCQE7BkHxNrSWFSKqOHo2H/UIR6YzAwYrEwmuMJ3hNdSEwfsO1z4an3bz45/YW0XShqfqiUU5YlLjdZ8gUijAMm1Au/8YK42uXrlz45UO/JYrPZEzVz9oKK2utoRo1fdc3zw0WRLFljP0Ozo03coN33yoxJECVm9gmVSDFU4oqXXSwmQTeB5Rw1M/ySykzG9Qbbn9IdsCWVXHkAzC97WxJlytfZUpafdA6iO8EJ6JKKo3a0kfuWKUSZ8qcWs8nnGTUWON
	
юзеру достаточно обновить свой файл 

	online/AAAAB3Nz/aC1yc2EA/AAADAQAB/AAA.....nGTUWON/online.info

в котором прописать свои `p2p контакты` это адреса для открытых сервисов p2plib , внешние адреса от stun, прочие адреса ipv6 итид. 

чтобы получать прямые соединения от других участников. **контент следует подписать.**


Контейнеры с данными
=====================

контейнер - это целевая единица синхронизациии (не факт что он будет весь синхронизирован), - аналог базы данных. 

Данные в нем (контейнере) хранятся в сжатом виде. 

**ИД контейнеру** выдается сразу и не меняется - генерируется УУИД. 
в контейнере есть таблицы (абстракция) с объектами в виде csv файлов . 

> вариант транспорта: каждый пользователь может для контейнера делать торрент и выкладывать его периодически в публичное пространство, 
> скачивание всех этих торрентов - есть сумма всех таблиц. 

Файлы юзеров могут выглядеть так  для контейнера с УУИД c1e9b221-2292-4963-ad68-fe2ef07d7b78 у юзера  45c8800d889fb48dff5 (каждый ид бьём на 3 части)

```
cnt/c1e9b221/2292/4963/ad68/fe2ef07d7b78/user/45c8800d/889fb4/8dff5/c1e9b221-2292-4963-ad68-fe2ef07d7b78--45c8800d889fb48dff5.torrent
cnt/c1e9b221/2292/4963/ad68/fe2ef07d7b78/user/45c8800d/889fb4/8dff5/c1e9b221-2292-4963-ad68-fe2ef07d7b78--45c8800d889fb48dff5.torrent.sign
....
```

по идее ТУТ должна быть инфа не только для торрентов. но и ipfs folder id c подписью.

**???????? тут недо-проектировал .** 

> это торренты всего контейнера от каждого юзера... **это транспорт**!!!??  
>
> я почему то сразу думаю о транспорте... плохо. 



Структура контейнера 
---------------------

```
files/  - важно отделить сами файлы от таблиц, чтобы клиент не скачивал их сразу
tables/ - файлы с вставками в таблицы по датам например `nodes-2022-05-31.csv` 
	структура по рекомендации выше (где 	`nodes` - имя таблицы)
files.csv - хеши файлов в разных системах для поиска
? mirrors.csv - куда контейнер реплицируется у автора, насройки репликации ( **стоит ли их публиковать? ведь это лишняя инфа для врагов?**  )
online/ - инфа о юзерах
sha256.summ 
sha256.summ.sign
md5.summ
md5.summ.sign
..... 
```

### считаем хеши для всего контейнера

считать эти хеши для контейнера можно так :

```
$ find . -type f | xargs sha256sum 
bf0673f690600fe0e668ddd0c66fab23ea1e94b86d5f308504fa7a6d9ce844d3  ./kladr.zip
00b36b0468c9c6d3f8355b6f1a802ead427307ce87cc65682bf184a9d54059da  ./git-work.md
2d71f00c1d6fa7b123bc6cdc4eb9c3bdc2c87961ab148fdb68608f1c34675638  ./postcodeToGeo.db

$ find . -type f | xargs md5sum | awk '{print($1, "\"" $2 "\"");}'
0da6bce0cd0e37fa38abfbb6d1aadf13 "./kladr.zip"
aaa494f922fc509bb1a6f359af83b6ec "./git-work.md"
3b422a8425d7bcb219f0981043ca40d5 "./postcodeToGeo.db"
....
```


​	
Вопросы
--------

нужна ли общая структура папок если есть контейнеры и торренты? 

```
> торренты это одно из возможных транспортных решений. 
> контейнер - файловое хранилище юзера
```

почему бы не иметь в контейнере каждого юзера ТОЛЬКО его личную акуальную полную версию?  и не иметь старых объектов ? 
т.е. делать часто GC ? 

```
> тогда история изменений будет недоступна. 
> версии объективно существуют - контейнер выглядит у каждого юзера не одинаково - это зависит от наличия интернета, жалания человека забирать чужие изменения итд.
> версия контейнера у каждого человека такая какая есть - это личное дело каждого человека. 
> если будет только актуальная версия - юзеры смогут переписывать историю и это будет не заметно и концов будет не найти. с историей же все правки подписаны ключами и можно, при желании, найти кто и что сделал.
> заплатки на объект могут перекрывать друг друга ссылаясь на старое уже удаленное значение и заплатку будет не проверить, а так - у заплатки будет предыстория.
> **важно : нужно индицировать, что в истории объекта есть конфликт значений. надо какой то индикатор**. про умолчанию юзер видит свои правки и не видит чужие, 
> но индикация показывает что конфликт есть. когда правка учтена , конфликт разрешается так-что новая версия ссылается на "друга" а своя помечается как удаленная. 
> **конфликт не будет отображаться если другие версии помечены как удаленные, на удаление надо иметь право**

с правами пока сложно... делаю простую версия proof-of-concept
```


Задача: стандартизировать структуру контейнера
==============================================

Получается это краеугольная задача. **стандартная файловая структура контейнера**

**требования**

* человек просто синхронизирует папку контейнера любым образом, 
* имена файлов не должны пересекаться
* папки одинаковые - они сливаются 

	```
	# типа того
	cat tables/node/*.csv | ........ 
	cat 
	```

