# Korni3  - это переизобретение "ksql on Kafka" для "реальной жизни"

## Концепт

Это полностью асинхронная система "хранения и управления данными для сервисов и приложений" (типа БД).

Консистентная "в конечном счёте". Многоверсионность - у каждого пользователя может быть своя версия данных. 

Система, архитектурно, *подразумевает* транспортный слой данных (учитывается сама возможность), но **не имеет транспортного и сетевого слоя** -  т.е. задача передачи данных не решается. Так сделано специально, чтобы не возможно было предъявить "распространение контента" (запрещенного, нежелательно и вообще любого). Самого факта "распространения" просто не будет. (юридические особенности читать в отдельных местах)

*Правки могут успешно проходить т.к. о запрете на них данному пользователю может быть еще не известно.* - + пока система прав не реализована и ее необходимость под вопросом. 

*Изменения от пользователя у других пользователей не будут отображаться если им известно о запрете таких правок от хозяина контента.* - не реализовано т.к. понятие "хозяин контента" под вопросом. 

Пользователи сами скачивают и получают ~~контент~~  данные (тут специально зачеркнуто написал , чтобы акцентировать) , сами решают что скачивать и каким способом (способов синхронизации файлов/данных очень много). Есть особые оригинальные предложения по лицензированию этих данных (в отдельном документе). После этого никакие претензии пользователей не принимаются. В публичном пространстве предоставляются только хеши, т.е. "обезличенно". 

Юридически система позволяет сопротивляться любому виду цензуры. 

## Использование

* утилита командной строки, которая может: 
  *  SQL FOR READ data . \ NO DML
  * Выборка, фильтрация , сортировка, группировка
  * вставка значений в БД
* изменение имеющихся данных невозможно, но возможна вставка новых версий значений, фактически дописывание файлы в папках, файлы  (возможна компактизация данных - после индивидуального решения)
* Данные хранятся в jsonnl (gz) файлах в специальной структуре папок, которая предназначена для синхронизации данных многих пользователей
* чтение sql может создавать временные или постоянные БД. т.е. **наличие БД - не обязательно и не существенно**, это технические детали реализации. т.е. формально есть sql а бд может быть а может и не быть. (о использовании конкретной субд например, речь не идет и она не гарантируется.)



## Критика ksql  и почему kafka  не устраивает

Мне для корпоративных систем импонирует использовать этот подход. Однако для текущей задачи я посчитал возможным его не использовать. 

### Факты о критикуемом решении (ksql  on kafka) \\\ <u>перенести в отдельный файл</u>

1. Kafka - быстрый файловый журнал и большим зоопарком конекторов. в том числе консольных. 
2. Это распределенное решение с центральным брокером (функционально это центральное звено является  структурно распределенным). Брокер ZooKeper это многоузловое приложение которое обеспечивает журналу kafka на каждой из партиций последовательную запись. 
3. журнал kafka разбит на партиции, в рамках партиции записи всегда последовательны, если доступны другие партиции , то можно рассматривать последовательность записей вообще, но они могут быть недоступны... Последовательность имеет смысл в строгом смысле только в рамках партиций. 
4. kafka обладает разумной файловой структурой : 
   1. файлы ограниченного размера с записями, которые дополняются
   2. отдельно файлы индекса, где номер записи => позиция в файле. 
   3. индекс содержит не все записи, а только 1/6 их часть - экономия места. 
   4. в целом по журналу доступ по номеру записи 3-10 сик операций, что не плохо
5. записи имеют ключ, компактизация по ключу позволяет оставить только последнюю версию для каждого ключа. это позволяет заранее разумно указывая ключ управлять компактизацией потом. 
6. pub/sub система идет в комплекте к журналу, можно читать с указанной позиции указанные топики и партиции - так можно организовать потоковую обработку даннных. 
7. ksql - надстройка над потоковой обработкой, позвляет публиковать и выбирать записи опираясь на sql dataflow. получается как бы  sql dbms поверех kafka - очень хорошее решение для IoT или больших систем обработки и хранения данных КОРПОРАТИВНОГО УРОВНЯ, (подразумевается кластер)

### сама Критика

у меня софт должен работать на слабом десктопном компьютере

* ZooKeper - громоздкий, это тяжелое серверное решение, предназначено для сверх большой нагрузки и любых стечений обстоятельств - у меня софт должен работать на слабом десктопном компьютере
* Брокер управляет кластером и кафка не синхронизирует журналы между машинами  в смысле синхронизации файлов, эти файлы нельзя просто смержить. их имена это 000000000012 например на каждой из узлов содержат разные данные.  Мы не можем мержить файловые базы с разных узлов кафка
* ksql строит индексы на мощностях кафка, т.е. бинарные деревья невозможны - только полный скан. 
* файлы кафка - записи журнала, а мне хотелось бы работать сразу с записями таблиц, чтобы легче интегрироваться с другими системами

Главная проблема : невозможность из множества отдельных серверов кафок перейти к общему набору данных так, чтобы даже не получая всех данных иметь возможность с ними работать. это связано в частности с жёсткой последовательностью журнала и для многопользовательского случая необходимостью разрывать журнал для вставок данных других пользователей после того как журнал сформирован - для кафки это невозможно. 
